{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Word Tokenization](#word-tokenization)\n",
    "    * [Most Common Words](#most-common-words)\n",
    "    * [Feature Creation](#most-common-words-feature-creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tweets dataset, this is a cut down version of the full tweet \n",
    "# dataset per the operations performed in the file \"eda-rea-v-liv-2018\"\n",
    "en_tweets_df = pd.read_csv('en_tweets_df.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>created_at_hour_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 13:18:30+00:00</td>\n",
       "      <td>{'id': 2846595478, 'id_str': '2846595478', 'na...</td>\n",
       "      <td>MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @ECG_Unofficial: We will like to categorica...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 11:14:44 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 902735000445095938, 'id_str': '90273500...</td>\n",
       "      <td>RT @ECG_Unofficial: We will like to categorica...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 240672622, 'id_str': '240672622', 'name...</td>\n",
       "      <td>Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 13:13:45 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 277019564, 'id_str': '277019564', 'name...</td>\n",
       "      <td>RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @ChampionsLeague: Two European giants go he...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 13:00:01 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 957644286350315521, 'id_str': '95764428...</td>\n",
       "      <td>RT @ChampionsLeague: Two European giants go he...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            id  \\\n",
       "0           0  1.000366e+18   \n",
       "1           4  1.000366e+18   \n",
       "2           5  1.000366e+18   \n",
       "3           7  1.000366e+18   \n",
       "4           8  1.000366e+18   \n",
       "\n",
       "                                                text lang  \\\n",
       "0  MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...   en   \n",
       "1  RT @ECG_Unofficial: We will like to categorica...   en   \n",
       "2  Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...   en   \n",
       "3  RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...   en   \n",
       "4  RT @ChampionsLeague: Two European giants go he...   en   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0                                                NaN   \n",
       "1  {'created_at': 'Sat May 26 11:14:44 +0000 2018...   \n",
       "2                                                NaN   \n",
       "3  {'created_at': 'Sat May 26 13:13:45 +0000 2018...   \n",
       "4  {'created_at': 'Sat May 26 13:00:01 +0000 2018...   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2018-05-26 13:18:30+00:00   \n",
       "1  2018-05-26 13:18:31+00:00   \n",
       "2  2018-05-26 13:18:31+00:00   \n",
       "3  2018-05-26 13:18:31+00:00   \n",
       "4  2018-05-26 13:18:31+00:00   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'id': 2846595478, 'id_str': '2846595478', 'na...   \n",
       "1  {'id': 902735000445095938, 'id_str': '90273500...   \n",
       "2  {'id': 240672622, 'id_str': '240672622', 'name...   \n",
       "3  {'id': 277019564, 'id_str': '277019564', 'name...   \n",
       "4  {'id': 957644286350315521, 'id_str': '95764428...   \n",
       "\n",
       "                                          tweet_text  is_retweet  \\\n",
       "0  MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...       False   \n",
       "1  RT @ECG_Unofficial: We will like to categorica...        True   \n",
       "2  Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...       False   \n",
       "3  RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...        True   \n",
       "4  RT @ChampionsLeague: Two European giants go he...        True   \n",
       "\n",
       "      created_at_hour_minute  \n",
       "0  2018-05-26 13:18:00+00:00  \n",
       "1  2018-05-26 13:18:00+00:00  \n",
       "2  2018-05-26 13:18:00+00:00  \n",
       "3  2018-05-26 13:18:00+00:00  \n",
       "4  2018-05-26 13:18:00+00:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jamie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/jamie/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NLTK libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Tokenization <a class=\"anchor\" id=\"word-tokenization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns clean tokenized words for a tweet\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Context specific stop words (refer \"most common words\" section below for identification approach\n",
    "# rt = short for retweet, this does not provide any insights and a column already exists to identify retweets\n",
    "# http & https = the start of web links these provide little value as \"words\", future work: these could be\n",
    "# to build a feature along thelines of \"Contains Web Link?\"\n",
    "# uclfinal, championsleague, championsleaguefinal = \"hashtag\"/topical words, given the original tweet dataset\n",
    "# contained only tweets that had a hashtag of uclfinal these words do not add value to the analysis\n",
    "custom_stopwords = ['rt', 'http', 'https', 'uclfinal', 'championsleague', 'championsleaguefinal']\n",
    "\n",
    "# Combine the two stop words lists\n",
    "stop_words = english_stopwords + custom_stopwords\n",
    "\n",
    "def CleanTokenizedWords(tweet):\n",
    "    word_tokenized = word_tokenize(tweet)\n",
    "\n",
    "    # lowercasing\n",
    "    cleaned_word_tokenized = [word.lower().strip() for word in word_tokenized]\n",
    "    \n",
    "    # replacing some unwanted things\n",
    "    cleaned_word_tokenized = [word.replace('(','').replace(')','') for word in cleaned_word_tokenized if word.isalpha()]\n",
    "    \n",
    "    # removing stopwords\n",
    "    cleaned_word_tokenized = [word for word in cleaned_word_tokenized if word not in stop_words]\n",
    "    \n",
    "    return cleaned_word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words in tweets\n",
    "en_tweets_df['tokenized_words'] = en_tweets_df.apply(lambda row: CleanTokenizedWords(row['tweet_text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words <a class=\"anchor\" id=\"most-common-words\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('salah', 37563),\n",
       " ('ramos', 31930),\n",
       " ('liverpool', 30926),\n",
       " ('bale', 22289),\n",
       " ('madrid', 22036),\n",
       " ('real', 20639),\n",
       " ('lfc', 16149),\n",
       " ('goal', 16090),\n",
       " ('sergio', 14423),\n",
       " ('gareth', 11287),\n",
       " ('final', 9889),\n",
       " ('world', 8590),\n",
       " ('mo', 8545),\n",
       " ('karius', 8490),\n",
       " ('one', 7878),\n",
       " ('ronaldo', 7447),\n",
       " ('cup', 7327),\n",
       " ('shoulder', 7185),\n",
       " ('like', 6794),\n",
       " ('game', 6668),\n",
       " ('ever', 6384),\n",
       " ('realmadrid', 6346),\n",
       " ('league', 5829),\n",
       " ('best', 5723),\n",
       " ('champions', 5498),\n",
       " ('time', 5319),\n",
       " ('vs', 5227),\n",
       " ('tears', 5223),\n",
       " ('goals', 5080),\n",
       " ('see', 4987),\n",
       " ('zidane', 4929),\n",
       " ('live', 4838),\n",
       " ('season', 4769),\n",
       " ('way', 4618),\n",
       " ('mosalah', 4550),\n",
       " ('win', 4528),\n",
       " ('fans', 4456),\n",
       " ('retweet', 4383),\n",
       " ('get', 4317),\n",
       " ('sad', 4317),\n",
       " ('football', 4277),\n",
       " ('first', 4274),\n",
       " ('watch', 4270),\n",
       " ('miss', 4102),\n",
       " ('go', 4021),\n",
       " ('rmaliv', 3931),\n",
       " ('dislocated', 3823),\n",
       " ('cristiano', 3778),\n",
       " ('injury', 3778),\n",
       " ('halamadrid', 3765),\n",
       " ('mane', 3740),\n",
       " ('mohamed', 3733),\n",
       " ('reds', 3675),\n",
       " ('ucl', 3668),\n",
       " ('bbc', 3659),\n",
       " ('tonight', 3613),\n",
       " ('reporting', 3528),\n",
       " ('diagnosis', 3527),\n",
       " ('adriandelmonte', 3485),\n",
       " ('come', 3382),\n",
       " ('kiev', 3379),\n",
       " ('injured', 3368),\n",
       " ('benzema', 3358),\n",
       " ('finish', 3318),\n",
       " ('carvajal', 3191),\n",
       " ('far', 3105),\n",
       " ('fuck', 3095),\n",
       " ('player', 3092),\n",
       " ('pitch', 3061),\n",
       " ('night', 2928),\n",
       " ('hate', 2915),\n",
       " ('score', 2872),\n",
       " ('dirty', 2866),\n",
       " ('man', 2771),\n",
       " ('btsportfootball', 2770),\n",
       " ('half', 2644),\n",
       " ('scores', 2614),\n",
       " ('disgrace', 2609),\n",
       " ('look', 2593),\n",
       " ('dua', 2549),\n",
       " ('match', 2510),\n",
       " ('team', 2499),\n",
       " ('allez', 2496),\n",
       " ('let', 2435),\n",
       " ('take', 2417),\n",
       " ('leaves', 2350),\n",
       " ('back', 2345),\n",
       " ('greatest', 2344),\n",
       " ('right', 2338),\n",
       " ('bleacherreport', 2335),\n",
       " ('stream', 2297),\n",
       " ('espnfc', 2267),\n",
       " ('think', 2264),\n",
       " ('forced', 2246),\n",
       " ('maddockmirror', 2208),\n",
       " ('dualipa', 2199),\n",
       " ('early', 2182),\n",
       " ('cynical', 2180),\n",
       " ('ended', 2167),\n",
       " ('better', 2131)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three key benefits to finding the most common words:\n",
    "    # 1. Further refinements could be made to CleanTokenizedWords in terms of words to exclude\n",
    "    # 2. We can obtain further insights into the data\n",
    "    # 3. Can select key words that could be used to generate features    \n",
    "\n",
    "# Convert tokenized words column into a single list of words\n",
    "words_list = en_tweets_df['tokenized_words'].values.tolist()\n",
    "\n",
    "# Flatten the list\n",
    "flattened_words_list = [j for sub in words_list for j in sub]\n",
    "\n",
    "# Find the most common words\n",
    "fdist = FreqDist(x.lower() for x in flattened_words_list)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation  <a class=\"anchor\" id=\"most-common-words-feature-creation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used to create a feature column for the most common words\n",
    "def WordFrequency(tokenized_words, word):\n",
    "    return tokenized_words.count(word)\n",
    "    \n",
    "\n",
    "def FeatureCreation(list_of_words):\n",
    "    for word in list_of_words:\n",
    "        en_tweets_df['FT_' + word + '_frequency'] = en_tweets_df.apply(lambda row: WordFrequency(row['tokenized_words'], word), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features for the top 100 words\n",
    "FeatureCreation([i[0] for i in fdist.most_common(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models <a class=\"anchor\" id=\"most-common-words-models\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Useful snippets etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  en_tweets_df:  2.1 GiB\n",
      "                            _7:  2.1 GiB\n",
      "                           _23:  2.1 GiB\n",
      "                           _31:  2.1 GiB\n",
      "                           _26:  1.9 GiB\n",
      "                           _62: 30.3 MiB\n",
      "                           _20: 11.2 MiB\n",
      "          flattened_words_list: 10.5 MiB\n",
      "                           _41:  1.9 MiB\n",
      "                           _35:  1.6 MiB\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# Memory usage https://stackoverflow.com/questions/16261240/releasing-memory-of-huge-numpy-array-in-ipython/16278056\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
