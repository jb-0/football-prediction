{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Word Tokenization](#word-tokenization)\n",
    "    * [Most Common Words](#most-common-words)\n",
    "    * [Feature Creation](#most-common-words-feature-creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tweets dataset, this is a cut down version of the full tweet \n",
    "# dataset per the operations performed in the file \"eda-rea-v-liv-2018\"\n",
    "en_tweets_df = pd.read_csv('en_tweets_df.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this dataset is generated from earlier work it carries its prior index, the below changes the column name\n",
    "en_tweets_df.rename(columns={'Unnamed: 0':'original_df_index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Tokenization <a class=\"anchor\" id=\"word-tokenization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns tokenizes, cleans and stems words for a tweet\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Context specific stop words (refer \"most common words\" section below for identification approach\n",
    "# rt = short for retweet, this does not provide any insights and a column already exists to identify retweets\n",
    "# http & https = the start of web links these provide little value as \"words\", future work: these could be\n",
    "# to build a feature along thelines of \"Contains Web Link?\"\n",
    "# uclfinal, championsleague, championsleaguefinal = \"hashtag\"/topical words, given the original tweet dataset\n",
    "# contained only tweets that had a hashtag of uclfinal these words do not add value to the analysis\n",
    "custom_stopwords = ['rt', 'http', 'https', 'uclfinal', 'championsleague', 'championsleaguefinal']\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Combine the two stop words lists\n",
    "stop_words = english_stopwords + custom_stopwords\n",
    "\n",
    "def TokenizeTweet(tweet):\n",
    "    word_tokenized = word_tokenize(tweet)\n",
    "\n",
    "    # lowercasing\n",
    "    cleaned_words_tokenized = [word.lower().strip() for word in word_tokenized]\n",
    "    \n",
    "    # replacing some unwanted things\n",
    "    cleaned_words_tokenized = [word.replace('(','').replace(')','') for word in cleaned_words_tokenized if word.isalpha()]\n",
    "    \n",
    "    # removing stopwords\n",
    "    cleaned_words_tokenized = [word for word in cleaned_words_tokenized if word not in stop_words]\n",
    "    \n",
    "    # stemming\n",
    "    cleaned_words_tokenized = [ps.stem(word) for word in cleaned_words_tokenized]\n",
    "    \n",
    "    return cleaned_words_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words in tweets\n",
    "en_tweets_df['tokenized_words'] = en_tweets_df.apply(lambda row: TokenizeTweet(row['tweet_text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words <a class=\"anchor\" id=\"most-common-words\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liverpool', 12458),\n",
       " ('ramo', 7507),\n",
       " ('salah', 7506),\n",
       " ('madrid', 7062),\n",
       " ('bale', 5764),\n",
       " ('real', 5611),\n",
       " ('goal', 5504),\n",
       " ('lfc', 4165),\n",
       " ('game', 3903),\n",
       " ('kariu', 3770),\n",
       " ('realmadrid', 3190),\n",
       " ('final', 2797),\n",
       " ('go', 2743),\n",
       " ('halamadrid', 2707),\n",
       " ('win', 2690),\n",
       " ('like', 2629),\n",
       " ('fuck', 2458),\n",
       " ('ronaldo', 2446),\n",
       " ('get', 2320),\n",
       " ('play', 2230),\n",
       " ('watch', 2190),\n",
       " ('rmaliv', 2183),\n",
       " ('come', 2164),\n",
       " ('live', 2005),\n",
       " ('player', 1885),\n",
       " ('one', 1884),\n",
       " ('sergio', 1878),\n",
       " ('fan', 1829),\n",
       " ('champion', 1817),\n",
       " ('mo', 1746),\n",
       " ('see', 1708),\n",
       " ('footbal', 1696),\n",
       " ('score', 1646),\n",
       " ('team', 1618),\n",
       " ('time', 1603),\n",
       " ('gareth', 1549),\n",
       " ('leagu', 1547),\n",
       " ('look', 1476),\n",
       " ('match', 1396),\n",
       " ('mane', 1377),\n",
       " ('mosalah', 1364),\n",
       " ('world', 1353),\n",
       " ('good', 1336),\n",
       " ('best', 1289),\n",
       " ('ucl', 1272),\n",
       " ('vs', 1242),\n",
       " ('need', 1238),\n",
       " ('man', 1232),\n",
       " ('injur', 1218),\n",
       " ('gt', 1213),\n",
       " ('ynwa', 1189),\n",
       " ('let', 1186),\n",
       " ('hope', 1183),\n",
       " ('well', 1152),\n",
       " ('injuri', 1152),\n",
       " ('tonight', 1128),\n",
       " ('first', 1125),\n",
       " ('feel', 1096),\n",
       " ('half', 1070),\n",
       " ('take', 1067),\n",
       " ('make', 1064),\n",
       " ('red', 1051),\n",
       " ('cup', 1030),\n",
       " ('back', 985),\n",
       " ('stream', 980),\n",
       " ('want', 980),\n",
       " ('even', 972),\n",
       " ('got', 970),\n",
       " ('oh', 968),\n",
       " ('cri', 968),\n",
       " ('think', 967),\n",
       " ('know', 963),\n",
       " ('still', 918),\n",
       " ('never', 915),\n",
       " ('would', 915),\n",
       " ('realli', 898),\n",
       " ('sergioramo', 894),\n",
       " ('dirti', 887),\n",
       " ('way', 866),\n",
       " ('ever', 852),\n",
       " ('love', 846),\n",
       " ('liverpoolfc', 844),\n",
       " ('better', 836),\n",
       " ('right', 832),\n",
       " ('benzema', 832),\n",
       " ('start', 806),\n",
       " ('keeper', 799),\n",
       " ('wow', 784),\n",
       " ('minut', 772),\n",
       " ('tear', 759),\n",
       " ('shit', 752),\n",
       " ('na', 723),\n",
       " ('great', 708),\n",
       " ('done', 708),\n",
       " ('say', 708),\n",
       " ('zidan', 704),\n",
       " ('goalkeep', 702),\n",
       " ('hate', 698),\n",
       " ('amp', 687),\n",
       " ('guy', 678),\n",
       " ('carvaj', 667),\n",
       " ('end', 659),\n",
       " ('ca', 650),\n",
       " ('liverpoolvsrealmadrid', 645),\n",
       " ('pleas', 637),\n",
       " ('sad', 636),\n",
       " ('bad', 634),\n",
       " ('god', 628),\n",
       " ('season', 620),\n",
       " ('cristiano', 619),\n",
       " ('rmalfc', 618),\n",
       " ('happen', 615),\n",
       " ('walk', 611),\n",
       " ('pitch', 607),\n",
       " ('save', 607),\n",
       " ('isco', 605),\n",
       " ('absolut', 603),\n",
       " ('klopp', 596),\n",
       " ('today', 594),\n",
       " ('ball', 593),\n",
       " ('realmadridliverpool', 579),\n",
       " ('much', 578),\n",
       " ('deserv', 573),\n",
       " ('support', 572),\n",
       " ('could', 566),\n",
       " ('miss', 550),\n",
       " ('year', 549),\n",
       " ('uefa', 546),\n",
       " ('kick', 538),\n",
       " ('alway', 538),\n",
       " ('far', 536),\n",
       " ('give', 535),\n",
       " ('seen', 519),\n",
       " ('gon', 517),\n",
       " ('u', 513),\n",
       " ('big', 506),\n",
       " ('thank', 502),\n",
       " ('anoth', 498),\n",
       " ('two', 489),\n",
       " ('beauti', 484),\n",
       " ('day', 484),\n",
       " ('alon', 477),\n",
       " ('keep', 477),\n",
       " ('shoulder', 477),\n",
       " ('kiev', 470),\n",
       " ('us', 468),\n",
       " ('lose', 464),\n",
       " ('thing', 461),\n",
       " ('believ', 458),\n",
       " ('peopl', 457),\n",
       " ('alreadi', 447),\n",
       " ('night', 445),\n",
       " ('nava', 443),\n",
       " ('second', 439),\n",
       " ('heart', 424),\n",
       " ('chanc', 420),\n",
       " ('sorri', 417),\n",
       " ('leav', 417),\n",
       " ('last', 413),\n",
       " ('show', 412),\n",
       " ('break', 405),\n",
       " ('lol', 403),\n",
       " ('must', 402),\n",
       " ('next', 402),\n",
       " ('tri', 398),\n",
       " ('without', 397),\n",
       " ('mistak', 394),\n",
       " ('card', 391),\n",
       " ('stop', 385),\n",
       " ('realmadriden', 380),\n",
       " ('free', 375),\n",
       " ('boy', 375),\n",
       " ('sure', 374),\n",
       " ('though', 374),\n",
       " ('may', 371),\n",
       " ('moment', 366),\n",
       " ('someon', 361),\n",
       " ('dualipa', 361),\n",
       " ('knew', 360),\n",
       " ('amaz', 356),\n",
       " ('made', 355),\n",
       " ('trophi', 354),\n",
       " ('attack', 350),\n",
       " ('job', 349),\n",
       " ('actual', 347),\n",
       " ('call', 345),\n",
       " ('put', 344),\n",
       " ('damn', 344),\n",
       " ('min', 340),\n",
       " ('cunt', 337),\n",
       " ('shot', 335),\n",
       " ('foul', 334),\n",
       " ('away', 333),\n",
       " ('hell', 330),\n",
       " ('ye', 328),\n",
       " ('everi', 327),\n",
       " ('marcelo', 327),\n",
       " ('wait', 326),\n",
       " ('perform', 326),\n",
       " ('new', 323),\n",
       " ('work', 322),\n",
       " ('realliverpool', 321),\n",
       " ('retweet', 321),\n",
       " ('intent', 317),\n",
       " ('link', 314),\n",
       " ('kill', 311),\n",
       " ('shame', 311),\n",
       " ('full', 309),\n",
       " ('offsid', 308),\n",
       " ('arm', 308),\n",
       " ('life', 306),\n",
       " ('hand', 304),\n",
       " ('worst', 304),\n",
       " ('side', 301),\n",
       " ('heartbreak', 301),\n",
       " ('defend', 300),\n",
       " ('noth', 300),\n",
       " ('escort', 297),\n",
       " ('soon', 296),\n",
       " ('sport', 295),\n",
       " ('left', 295),\n",
       " ('winner', 294),\n",
       " ('close', 294),\n",
       " ('tell', 293),\n",
       " ('histori', 293),\n",
       " ('everyon', 293),\n",
       " ('went', 293),\n",
       " ('lost', 293),\n",
       " ('soccer', 292),\n",
       " ('livrma', 287),\n",
       " ('tackl', 282),\n",
       " ('hit', 282),\n",
       " ('egypt', 281),\n",
       " ('goe', 280),\n",
       " ('sinc', 275),\n",
       " ('word', 275),\n",
       " ('moham', 275),\n",
       " ('hd', 274),\n",
       " ('dua', 273),\n",
       " ('weareliverpool', 273),\n",
       " ('wonder', 272),\n",
       " ('pass', 272),\n",
       " ('also', 272),\n",
       " ('bet', 271),\n",
       " ('turn', 271),\n",
       " ('class', 271),\n",
       " ('earli', 270),\n",
       " ('hard', 269),\n",
       " ('someth', 268),\n",
       " ('said', 268),\n",
       " ('rm', 266),\n",
       " ('thought', 264),\n",
       " ('gut', 263),\n",
       " ('club', 261),\n",
       " ('poor', 261),\n",
       " ('fair', 258),\n",
       " ('v', 258),\n",
       " ('beat', 257),\n",
       " ('congratul', 257),\n",
       " ('news', 255),\n",
       " ('yet', 253),\n",
       " ('seem', 252),\n",
       " ('might', 250),\n",
       " ('hurt', 249),\n",
       " ('mean', 248),\n",
       " ('proud', 247),\n",
       " ('lori', 247),\n",
       " ('bring', 246),\n",
       " ('luck', 246),\n",
       " ('top', 245),\n",
       " ('bastard', 244),\n",
       " ('nice', 243),\n",
       " ('mani', 242),\n",
       " ('row', 242),\n",
       " ('finish', 241),\n",
       " ('field', 240),\n",
       " ('tv', 239),\n",
       " ('wtf', 238),\n",
       " ('anyon', 238),\n",
       " ('cheat', 237),\n",
       " ('head', 236),\n",
       " ('gone', 236),\n",
       " ('incred', 235),\n",
       " ('mobil', 235),\n",
       " ('talk', 235),\n",
       " ('twitter', 235),\n",
       " ('press', 235),\n",
       " ('chang', 235),\n",
       " ('tweet', 231),\n",
       " ('egyptian', 231),\n",
       " ('home', 229),\n",
       " ('long', 229),\n",
       " ('happi', 228),\n",
       " ('wish', 228),\n",
       " ('biggest', 226),\n",
       " ('imagin', 226),\n",
       " ('lallana', 226),\n",
       " ('plan', 226),\n",
       " ('open', 225),\n",
       " ('eye', 225),\n",
       " ('face', 220),\n",
       " ('high', 220),\n",
       " ('holi', 220),\n",
       " ('use', 220),\n",
       " ('respect', 219),\n",
       " ('level', 218),\n",
       " ('whole', 218),\n",
       " ('omg', 217),\n",
       " ('follow', 216),\n",
       " ('firmino', 214),\n",
       " ('bow', 214),\n",
       " ('uefachampionsleaguefin', 212),\n",
       " ('lipa', 210),\n",
       " ('lad', 210),\n",
       " ('allez', 209),\n",
       " ('unbeliev', 208),\n",
       " ('disgrac', 207),\n",
       " ('ruin', 205),\n",
       " ('fast', 204),\n",
       " ('pull', 204),\n",
       " ('bar', 204),\n",
       " ('expect', 202),\n",
       " ('sadio', 202),\n",
       " ('sub', 202),\n",
       " ('men', 199),\n",
       " ('stupid', 199),\n",
       " ('unit', 198),\n",
       " ('pain', 198),\n",
       " ('book', 196),\n",
       " ('three', 196),\n",
       " ('forc', 196),\n",
       " ('bitch', 196),\n",
       " ('robertson', 195),\n",
       " ('differ', 194),\n",
       " ('anyth', 194),\n",
       " ('move', 194),\n",
       " ('emot', 193),\n",
       " ('bicycl', 193),\n",
       " ('bit', 192),\n",
       " ('pressur', 192),\n",
       " ('goali', 192),\n",
       " ('mad', 191),\n",
       " ('purpos', 191),\n",
       " ('els', 190),\n",
       " ('rememb', 190),\n",
       " ('definit', 189),\n",
       " ('ref', 187),\n",
       " ('hold', 187),\n",
       " ('sallah', 185),\n",
       " ('lot', 184),\n",
       " ('hala', 183),\n",
       " ('okay', 183),\n",
       " ('came', 181),\n",
       " ('run', 180),\n",
       " ('wrong', 179),\n",
       " ('penalti', 179),\n",
       " ('king', 177),\n",
       " ('loriskariu', 176),\n",
       " ('reason', 175),\n",
       " ('touch', 175),\n",
       " ('manag', 174),\n",
       " ('refere', 173),\n",
       " ('greatest', 172),\n",
       " ('fc', 171),\n",
       " ('die', 171),\n",
       " ('complet', 171),\n",
       " ('offer', 170),\n",
       " ('modric', 169),\n",
       " ('took', 168),\n",
       " ('blow', 168),\n",
       " ('challeng', 166),\n",
       " ('exactli', 166),\n",
       " ('interest', 165),\n",
       " ('enjoy', 165),\n",
       " ('ok', 164),\n",
       " ('wo', 164),\n",
       " ('fire', 164),\n",
       " ('help', 163),\n",
       " ('son', 163),\n",
       " ('de', 162),\n",
       " ('im', 162),\n",
       " ('rmliv', 162),\n",
       " ('comment', 162),\n",
       " ('career', 162),\n",
       " ('almost', 161),\n",
       " ('probabl', 161),\n",
       " ('guess', 160),\n",
       " ('experi', 160),\n",
       " ('messi', 159),\n",
       " ('huge', 159),\n",
       " ('brilliant', 159),\n",
       " ('celebr', 158),\n",
       " ('usa', 157),\n",
       " ('point', 156),\n",
       " ('uefachampionsleagu', 155),\n",
       " ('dream', 155),\n",
       " ('everyth', 155),\n",
       " ('piec', 155),\n",
       " ('dont', 154),\n",
       " ('person', 153),\n",
       " ('error', 153),\n",
       " ('allezallezallez', 152),\n",
       " ('find', 152),\n",
       " ('disgust', 152),\n",
       " ('realmadridvsliverpool', 151),\n",
       " ('ta', 150),\n",
       " ('halamadid', 150),\n",
       " ('terribl', 150),\n",
       " ('aw', 150),\n",
       " ('mexico', 149),\n",
       " ('onlin', 149),\n",
       " ('saw', 149),\n",
       " ('english', 148),\n",
       " ('bench', 148),\n",
       " ('name', 148),\n",
       " ('kid', 148),\n",
       " ('crypto', 147),\n",
       " ('bitcoin', 147),\n",
       " ('care', 147),\n",
       " ('qualiti', 147),\n",
       " ('lmao', 146),\n",
       " ('around', 146),\n",
       " ('tho', 146),\n",
       " ('littl', 145),\n",
       " ('yearli', 145),\n",
       " ('membership', 145),\n",
       " ('costarica', 145),\n",
       " ('canada', 145),\n",
       " ('eeuu', 145),\n",
       " ('guatemala', 145),\n",
       " ('panama', 145),\n",
       " ('least', 145),\n",
       " ('fantast', 145),\n",
       " ('stand', 145),\n",
       " ('kind', 145),\n",
       " ('substitut', 145),\n",
       " ('liter', 144),\n",
       " ('enough', 144),\n",
       " ('part', 144),\n",
       " ('titl', 143),\n",
       " ('predict', 142),\n",
       " ('root', 142),\n",
       " ('gift', 142),\n",
       " ('congrat', 142),\n",
       " ('milner', 141),\n",
       " ('legend', 141),\n",
       " ('defens', 140),\n",
       " ('app', 139),\n",
       " ('corner', 139),\n",
       " ('dear', 138),\n",
       " ('fall', 138),\n",
       " ('lead', 138),\n",
       " ('disloc', 138),\n",
       " ('lovren', 137),\n",
       " ('surpris', 137),\n",
       " ('stage', 136),\n",
       " ('lift', 136),\n",
       " ('magic', 136),\n",
       " ('equal', 136),\n",
       " ('ridicul', 135),\n",
       " ('commentari', 134),\n",
       " ('sign', 133),\n",
       " ('reaction', 133),\n",
       " ('pray', 132),\n",
       " ('smh', 131),\n",
       " ('cross', 131),\n",
       " ('phone', 130),\n",
       " ('kyiv', 130),\n",
       " ('dey', 129),\n",
       " ('money', 129),\n",
       " ('super', 129),\n",
       " ('total', 129),\n",
       " ('third', 129),\n",
       " ('mayb', 128),\n",
       " ('tactic', 128),\n",
       " ('wrestl', 128),\n",
       " ('england', 127),\n",
       " ('post', 127),\n",
       " ('updat', 126),\n",
       " ('liv', 126),\n",
       " ('european', 126),\n",
       " ('matter', 126),\n",
       " ('strike', 126),\n",
       " ('caus', 126),\n",
       " ('ask', 125),\n",
       " ('deliber', 125),\n",
       " ('due', 124),\n",
       " ('stay', 124),\n",
       " ('profession', 124),\n",
       " ('cost', 124),\n",
       " ('remind', 124),\n",
       " ('karma', 124),\n",
       " ('carri', 123),\n",
       " ('fight', 123),\n",
       " ('mind', 123),\n",
       " ('domin', 123),\n",
       " ('consecut', 122),\n",
       " ('front', 122),\n",
       " ('matchday', 122),\n",
       " ('cl', 122)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three key benefits to finding the most common words:\n",
    "    # 1. Further refinements could be made to CleanTokenizedWords in terms of words to exclude\n",
    "    # 2. We can obtain further insights into the data\n",
    "    # 3. Can select key words that could be used to generate features    \n",
    "\n",
    "# Convert tokenized words column into a single list of words, ignoring retweets to get a true view on most frequently\n",
    "# tweeted words\n",
    "words_list = en_tweets_df['tokenized_words'][en_tweets_df['is_retweet']==False].values.tolist()\n",
    "\n",
    "# Flatten the list\n",
    "flattened_words_list = [j for sub in words_list for j in sub]\n",
    "\n",
    "# Find the most common words\n",
    "fdist = FreqDist(x.lower() for x in flattened_words_list)\n",
    "fdist.most_common(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation  <a class=\"anchor\" id=\"most-common-words-feature-creation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used to create a feature column for the most common words\n",
    "def WordFrequency(tokenized_words, word):\n",
    "    return tokenized_words.count(word)\n",
    "    \n",
    "\n",
    "def FeatureCreation(list_of_words, iteration):\n",
    "    for word in list_of_words:\n",
    "        en_tweets_df['FT_' + word + '_frequency'] = en_tweets_df.apply(lambda row: WordFrequency(row['tokenized_words'], word), axis=1)\n",
    "        print(f'{i}. Feature created for {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature created for liverpool\n",
      "Feature created for ramo\n",
      "Feature created for salah\n",
      "Feature created for madrid\n",
      "Feature created for bale\n",
      "Feature created for real\n",
      "Feature created for goal\n",
      "Feature created for lfc\n",
      "Feature created for game\n",
      "Feature created for kariu\n",
      "Feature created for realmadrid\n",
      "Feature created for final\n",
      "Feature created for go\n",
      "Feature created for halamadrid\n",
      "Feature created for win\n",
      "Feature created for like\n",
      "Feature created for fuck\n",
      "Feature created for ronaldo\n",
      "Feature created for get\n",
      "Feature created for play\n",
      "Feature created for watch\n",
      "Feature created for rmaliv\n",
      "Feature created for come\n",
      "Feature created for live\n",
      "Feature created for player\n",
      "Feature created for one\n",
      "Feature created for sergio\n",
      "Feature created for fan\n",
      "Feature created for champion\n",
      "Feature created for mo\n",
      "Feature created for see\n",
      "Feature created for footbal\n",
      "Feature created for score\n",
      "Feature created for team\n",
      "Feature created for time\n",
      "Feature created for gareth\n",
      "Feature created for leagu\n",
      "Feature created for look\n",
      "Feature created for match\n",
      "Feature created for mane\n",
      "Feature created for mosalah\n",
      "Feature created for world\n",
      "Feature created for good\n",
      "Feature created for best\n",
      "Feature created for ucl\n",
      "Feature created for vs\n",
      "Feature created for need\n",
      "Feature created for man\n",
      "Feature created for injur\n",
      "Feature created for gt\n",
      "Feature created for ynwa\n",
      "Feature created for let\n",
      "Feature created for hope\n",
      "Feature created for well\n",
      "Feature created for injuri\n",
      "Feature created for tonight\n",
      "Feature created for first\n",
      "Feature created for feel\n",
      "Feature created for half\n",
      "Feature created for take\n",
      "Feature created for make\n",
      "Feature created for red\n",
      "Feature created for cup\n",
      "Feature created for back\n",
      "Feature created for stream\n",
      "Feature created for want\n",
      "Feature created for even\n",
      "Feature created for got\n",
      "Feature created for oh\n",
      "Feature created for cri\n",
      "Feature created for think\n",
      "Feature created for know\n",
      "Feature created for still\n",
      "Feature created for never\n",
      "Feature created for would\n",
      "Feature created for realli\n",
      "Feature created for sergioramo\n",
      "Feature created for dirti\n",
      "Feature created for way\n",
      "Feature created for ever\n",
      "Feature created for love\n",
      "Feature created for liverpoolfc\n",
      "Feature created for better\n",
      "Feature created for right\n",
      "Feature created for benzema\n",
      "Feature created for start\n",
      "Feature created for keeper\n",
      "Feature created for wow\n",
      "Feature created for minut\n",
      "Feature created for tear\n",
      "Feature created for shit\n",
      "Feature created for na\n",
      "Feature created for great\n",
      "Feature created for done\n",
      "Feature created for say\n",
      "Feature created for zidan\n",
      "Feature created for goalkeep\n",
      "Feature created for hate\n",
      "Feature created for amp\n",
      "Feature created for guy\n",
      "Feature created for carvaj\n",
      "Feature created for end\n",
      "Feature created for ca\n",
      "Feature created for liverpoolvsrealmadrid\n",
      "Feature created for pleas\n",
      "Feature created for sad\n",
      "Feature created for bad\n",
      "Feature created for god\n",
      "Feature created for season\n",
      "Feature created for cristiano\n",
      "Feature created for rmalfc\n",
      "Feature created for happen\n",
      "Feature created for walk\n",
      "Feature created for pitch\n",
      "Feature created for save\n",
      "Feature created for isco\n",
      "Feature created for absolut\n",
      "Feature created for realmadridliverpool\n",
      "Feature created for much\n",
      "Feature created for deserv\n",
      "Feature created for support\n",
      "Feature created for could\n",
      "Feature created for miss\n",
      "Feature created for year\n",
      "Feature created for uefa\n",
      "Feature created for kick\n",
      "Feature created for alway\n",
      "Feature created for far\n",
      "Feature created for give\n",
      "Feature created for seen\n",
      "Feature created for gon\n",
      "Feature created for u\n",
      "Feature created for big\n",
      "Feature created for thank\n",
      "Feature created for anoth\n",
      "Feature created for two\n",
      "Feature created for beauti\n",
      "Feature created for day\n",
      "Feature created for alon\n",
      "Feature created for keep\n",
      "Feature created for shoulder\n",
      "Feature created for kiev\n",
      "Feature created for us\n",
      "Feature created for lose\n",
      "Feature created for thing\n",
      "Feature created for believ\n",
      "Feature created for peopl\n",
      "Feature created for alreadi\n",
      "Feature created for night\n",
      "Feature created for nava\n",
      "Feature created for second\n",
      "Feature created for heart\n",
      "Feature created for chanc\n",
      "Feature created for sorri\n",
      "Feature created for leav\n",
      "Feature created for last\n",
      "Feature created for show\n",
      "Feature created for break\n",
      "Feature created for lol\n",
      "Feature created for must\n",
      "Feature created for next\n",
      "Feature created for tri\n",
      "Feature created for without\n",
      "Feature created for mistak\n",
      "Feature created for card\n",
      "Feature created for stop\n",
      "Feature created for realmadriden\n",
      "Feature created for free\n",
      "Feature created for boy\n",
      "Feature created for sure\n",
      "Feature created for though\n",
      "Feature created for may\n",
      "Feature created for moment\n",
      "Feature created for someon\n",
      "Feature created for dualipa\n",
      "Feature created for knew\n",
      "Feature created for amaz\n",
      "Feature created for made\n",
      "Feature created for trophi\n",
      "Feature created for attack\n",
      "Feature created for job\n",
      "Feature created for actual\n",
      "Feature created for call\n",
      "Feature created for put\n",
      "Feature created for damn\n",
      "Feature created for min\n",
      "Feature created for cunt\n",
      "Feature created for shot\n",
      "Feature created for foul\n",
      "Feature created for away\n",
      "Feature created for hell\n",
      "Feature created for ye\n",
      "Feature created for everi\n",
      "Feature created for marcelo\n",
      "Feature created for wait\n",
      "Feature created for perform\n",
      "Feature created for new\n",
      "Feature created for work\n",
      "Feature created for realliverpool\n",
      "Feature created for retweet\n",
      "Feature created for intent\n",
      "Feature created for link\n",
      "Feature created for kill\n",
      "Feature created for shame\n",
      "Feature created for full\n",
      "Feature created for offsid\n",
      "Feature created for arm\n",
      "Feature created for life\n",
      "Feature created for hand\n",
      "Feature created for worst\n",
      "Feature created for side\n",
      "Feature created for heartbreak\n",
      "Feature created for defend\n",
      "Feature created for noth\n",
      "Feature created for escort\n",
      "Feature created for soon\n",
      "Feature created for sport\n",
      "Feature created for left\n",
      "Feature created for winner\n",
      "Feature created for close\n",
      "Feature created for tell\n",
      "Feature created for histori\n",
      "Feature created for everyon\n",
      "Feature created for went\n",
      "Feature created for lost\n",
      "Feature created for soccer\n",
      "Feature created for livrma\n",
      "Feature created for tackl\n",
      "Feature created for hit\n",
      "Feature created for egypt\n",
      "Feature created for goe\n",
      "Feature created for sinc\n",
      "Feature created for word\n",
      "Feature created for moham\n",
      "Feature created for hd\n",
      "Feature created for dua\n",
      "Feature created for weareliverpool\n",
      "Feature created for wonder\n",
      "Feature created for pass\n",
      "Feature created for also\n",
      "Feature created for bet\n",
      "Feature created for turn\n",
      "Feature created for class\n",
      "Feature created for earli\n",
      "Feature created for hard\n",
      "Feature created for someth\n",
      "Feature created for said\n",
      "Feature created for rm\n",
      "Feature created for thought\n",
      "Feature created for gut\n",
      "Feature created for club\n",
      "Feature created for poor\n",
      "Feature created for fair\n",
      "Feature created for v\n",
      "Feature created for beat\n",
      "Feature created for congratul\n",
      "Feature created for news\n",
      "Feature created for yet\n",
      "Feature created for seem\n",
      "Feature created for might\n",
      "Feature created for hurt\n",
      "Feature created for mean\n",
      "Feature created for proud\n",
      "Feature created for lori\n",
      "Feature created for bring\n",
      "Feature created for luck\n",
      "Feature created for top\n",
      "Feature created for bastard\n",
      "Feature created for nice\n",
      "Feature created for mani\n",
      "Feature created for row\n",
      "Feature created for finish\n",
      "Feature created for field\n",
      "Feature created for tv\n",
      "Feature created for wtf\n",
      "Feature created for anyon\n",
      "Feature created for cheat\n",
      "Feature created for head\n",
      "Feature created for gone\n",
      "Feature created for incred\n",
      "Feature created for mobil\n",
      "Feature created for talk\n",
      "Feature created for twitter\n",
      "Feature created for press\n",
      "Feature created for chang\n",
      "Feature created for tweet\n",
      "Feature created for egyptian\n",
      "Feature created for home\n",
      "Feature created for long\n",
      "Feature created for happi\n",
      "Feature created for wish\n",
      "Feature created for biggest\n",
      "Feature created for imagin\n",
      "Feature created for lallana\n",
      "Feature created for plan\n",
      "Feature created for open\n",
      "Feature created for eye\n",
      "Feature created for face\n",
      "Feature created for high\n",
      "Feature created for holi\n",
      "Feature created for use\n",
      "Feature created for respect\n",
      "Feature created for level\n",
      "Feature created for whole\n",
      "Feature created for omg\n",
      "Feature created for follow\n",
      "Feature created for firmino\n",
      "Feature created for bow\n",
      "Feature created for uefachampionsleaguefin\n",
      "Feature created for lipa\n",
      "Feature created for lad\n",
      "Feature created for allez\n",
      "Feature created for unbeliev\n",
      "Feature created for disgrac\n",
      "Feature created for ruin\n",
      "Feature created for fast\n",
      "Feature created for pull\n",
      "Feature created for bar\n",
      "Feature created for expect\n",
      "Feature created for sadio\n",
      "Feature created for sub\n",
      "Feature created for men\n",
      "Feature created for stupid\n",
      "Feature created for unit\n",
      "Feature created for pain\n",
      "Feature created for book\n",
      "Feature created for three\n",
      "Feature created for forc\n",
      "Feature created for bitch\n",
      "Feature created for robertson\n",
      "Feature created for differ\n",
      "Feature created for anyth\n",
      "Feature created for move\n",
      "Feature created for emot\n",
      "Feature created for bicycl\n",
      "Feature created for bit\n",
      "Feature created for pressur\n",
      "Feature created for goali\n",
      "Feature created for mad\n",
      "Feature created for purpos\n",
      "Feature created for els\n",
      "Feature created for rememb\n",
      "Feature created for definit\n",
      "Feature created for ref\n",
      "Feature created for hold\n",
      "Feature created for sallah\n",
      "Feature created for lot\n",
      "Feature created for hala\n",
      "Feature created for okay\n",
      "Feature created for came\n",
      "Feature created for run\n",
      "Feature created for wrong\n",
      "Feature created for penalti\n",
      "Feature created for king\n",
      "Feature created for loriskariu\n",
      "Feature created for reason\n",
      "Feature created for touch\n",
      "Feature created for manag\n",
      "Feature created for refere\n",
      "Feature created for greatest\n",
      "Feature created for fc\n",
      "Feature created for die\n",
      "Feature created for complet\n",
      "Feature created for offer\n",
      "Feature created for modric\n",
      "Feature created for took\n",
      "Feature created for blow\n",
      "Feature created for challeng\n",
      "Feature created for exactli\n",
      "Feature created for interest\n",
      "Feature created for enjoy\n",
      "Feature created for ok\n",
      "Feature created for wo\n",
      "Feature created for fire\n",
      "Feature created for help\n",
      "Feature created for son\n",
      "Feature created for de\n",
      "Feature created for im\n",
      "Feature created for rmliv\n",
      "Feature created for comment\n",
      "Feature created for career\n",
      "Feature created for almost\n",
      "Feature created for probabl\n",
      "Feature created for guess\n",
      "Feature created for experi\n",
      "Feature created for messi\n",
      "Feature created for huge\n",
      "Feature created for brilliant\n",
      "Feature created for celebr\n",
      "Feature created for usa\n",
      "Feature created for point\n",
      "Feature created for uefachampionsleagu\n",
      "Feature created for dream\n",
      "Feature created for everyth\n",
      "Feature created for piec\n",
      "Feature created for dont\n",
      "Feature created for person\n",
      "Feature created for error\n",
      "Feature created for allezallezallez\n",
      "Feature created for find\n",
      "Feature created for disgust\n",
      "Feature created for realmadridvsliverpool\n",
      "Feature created for ta\n",
      "Feature created for halamadid\n",
      "Feature created for terribl\n",
      "Feature created for aw\n",
      "Feature created for mexico\n",
      "Feature created for onlin\n",
      "Feature created for saw\n",
      "Feature created for english\n",
      "Feature created for bench\n",
      "Feature created for name\n",
      "Feature created for kid\n",
      "Feature created for crypto\n",
      "Feature created for bitcoin\n",
      "Feature created for care\n",
      "Feature created for qualiti\n",
      "Feature created for lmao\n",
      "Feature created for around\n",
      "Feature created for tho\n",
      "Feature created for littl\n",
      "Feature created for yearli\n",
      "Feature created for membership\n",
      "Feature created for costarica\n",
      "Feature created for canada\n",
      "Feature created for eeuu\n",
      "Feature created for guatemala\n",
      "Feature created for panama\n",
      "Feature created for least\n",
      "Feature created for fantast\n",
      "Feature created for stand\n",
      "Feature created for kind\n",
      "Feature created for substitut\n",
      "Feature created for liter\n",
      "Feature created for enough\n",
      "Feature created for part\n",
      "Feature created for titl\n",
      "Feature created for predict\n",
      "Feature created for root\n",
      "Feature created for gift\n",
      "Feature created for congrat\n",
      "Feature created for milner\n",
      "Feature created for legend\n",
      "Feature created for defens\n",
      "Feature created for app\n",
      "Feature created for corner\n",
      "Feature created for dear\n",
      "Feature created for fall\n",
      "Feature created for lead\n",
      "Feature created for disloc\n",
      "Feature created for lovren\n",
      "Feature created for surpris\n",
      "Feature created for stage\n",
      "Feature created for lift\n",
      "Feature created for magic\n",
      "Feature created for equal\n",
      "Feature created for ridicul\n",
      "Feature created for commentari\n",
      "Feature created for sign\n",
      "Feature created for reaction\n",
      "Feature created for pray\n",
      "Feature created for smh\n",
      "Feature created for cross\n",
      "Feature created for phone\n",
      "Feature created for kyiv\n",
      "Feature created for dey\n",
      "Feature created for money\n",
      "Feature created for super\n",
      "Feature created for total\n",
      "Feature created for third\n",
      "Feature created for mayb\n",
      "Feature created for tactic\n",
      "Feature created for wrestl\n",
      "Feature created for england\n",
      "Feature created for post\n",
      "Feature created for updat\n",
      "Feature created for liv\n",
      "Feature created for european\n",
      "Feature created for matter\n",
      "Feature created for strike\n",
      "Feature created for caus\n",
      "Feature created for ask\n",
      "Feature created for deliber\n",
      "Feature created for due\n",
      "Feature created for stay\n",
      "Feature created for profession\n",
      "Feature created for cost\n",
      "Feature created for remind\n",
      "Feature created for karma\n",
      "Feature created for carri\n",
      "Feature created for fight\n",
      "Feature created for mind\n",
      "Feature created for domin\n",
      "Feature created for consecut\n",
      "Feature created for front\n",
      "Feature created for matchday\n",
      "Feature created for cl\n"
     ]
    }
   ],
   "source": [
    "# Create features for the top 500 words\n",
    "FeatureCreation([i[0] for i in fdist.most_common(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of feature columns, output length of list\n",
    "cols = [col for col in en_tweets_df.columns if col[:3] == 'FT_']\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe shape: (188087, 512)\n",
      "With features dataframe shape: (181317, 512)\n"
     ]
    }
   ],
   "source": [
    "# If tweets do not contain any of the 500 most common words then there are no insights into the topic\n",
    "# the below is used to drop such cases\n",
    "en_tweets_df['sum_of_FT_cols'] = en_tweets_df[cols].sum(axis=1)\n",
    "en_tweets_df_with_features = en_tweets_df[en_tweets_df['sum_of_FT_cols'] != 0]\n",
    "print(f'Original dataframe shape: {en_tweets_df.shape}')\n",
    "print(f'With features dataframe shape: {en_tweets_df_with_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models <a class=\"anchor\" id=\"most-common-words-models\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans <a class=\"anchor\" id=\"most-common-words-kmeans\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(3, 11):\n",
    "    for num_of_FT_cols in range(25, 501, 25):\n",
    "        X = en_tweets_df_with_features[cols[:num_of_FT_cols]]\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k, random_state=8)\n",
    "        kmeans.fit(X)\n",
    "        y_kmeans = kmeans.predict(X)\n",
    "        \n",
    "        # Print a number of tweets for each cluster\n",
    "        y = pd.Series(y_kmeans)\n",
    "        df_tweet_y = pd.DataFrame(en_tweets_df_with_features)\n",
    "        df_tweet_y['y'] = pd.Series(y)\n",
    "\n",
    "        pd.set_option('display.max_colwidth', None)\n",
    "        \n",
    "        print(f'------------------------------------------------------------------------')\n",
    "        print(f'------------------------------------------------------------------------')\n",
    "        print(f'k = {k} ---- Number of FT cols = {num_of_FT_cols}\\n')\n",
    "\n",
    "        for i in range(0, k + 1):\n",
    "            print(f'****************************************** \\n Cluster {i}')\n",
    "            print('******************************************')\n",
    "            print(df_tweet_y['tweet_text'][(df_tweet_y['y'] == i) & (df_tweet_y['is_retweet'] == False)].sample(5).to_string())\n",
    "            print('****************************************** \\n')\n",
    "            \n",
    "        print(f'------------------------------------------------------------------------')\n",
    "        print(f'------------------------------------------------------------------------\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 150\n",
    "X = en_tweets_df_with_features[cols[:25]]\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=8)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a number of tweets for each cluster\n",
    "y = pd.Series(y_kmeans)\n",
    "df_tweet_y = pd.DataFrame(en_tweets_df_with_features.tail(90000)) # The dataframeis ~180k, so sampled tweets are roughly from the middle of dataset\n",
    "df_tweet_y['y'] = pd.Series(y)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "for i in range(0, 50):\n",
    "    print(f'****************************************** \\n Cluster {i}')\n",
    "    print('******************************************')\n",
    "    print(df_tweet_y['tweet_text'][(df_tweet_y['y'] == i) & (df_tweet_y['is_retweet'] == False)].head(10).to_string())\n",
    "    print('****************************************** \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run PCA on the data and reduce the dimensions in pca_num_components dimensions\n",
    "reduced_data = PCA(n_components=2).fit_transform(X)\n",
    "results = pd.DataFrame(reduced_data,columns=['pca1','pca2'])\n",
    "\n",
    "plt.figure(figsize=(40,30))\n",
    "sns.scatterplot(x=\"pca1\", y=\"pca2\", hue=y_kmeans, data=results)\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Useful snippets etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Memory usage https://stackoverflow.com/questions/16261240/releasing-memory-of-huge-numpy-array-in-ipython/16278056\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
