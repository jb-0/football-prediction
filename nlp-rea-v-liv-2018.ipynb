{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tweets dataset, this is a cut down version of the full tweet \n",
    "# dataset per the operations performed in the file \"eda-rea-v-liv-2018\"\n",
    "en_tweets_df = pd.read_csv('en_tweets_df.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>created_at_hour_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 13:18:30+00:00</td>\n",
       "      <td>{'id': 2846595478, 'id_str': '2846595478', 'na...</td>\n",
       "      <td>MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @ECG_Unofficial: We will like to categorica...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 11:14:44 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 902735000445095938, 'id_str': '90273500...</td>\n",
       "      <td>RT @ECG_Unofficial: We will like to categorica...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 240672622, 'id_str': '240672622', 'name...</td>\n",
       "      <td>Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 13:13:45 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 277019564, 'id_str': '277019564', 'name...</td>\n",
       "      <td>RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000366e+18</td>\n",
       "      <td>RT @ChampionsLeague: Two European giants go he...</td>\n",
       "      <td>en</td>\n",
       "      <td>{'created_at': 'Sat May 26 13:00:01 +0000 2018...</td>\n",
       "      <td>2018-05-26 13:18:31+00:00</td>\n",
       "      <td>{'id': 957644286350315521, 'id_str': '95764428...</td>\n",
       "      <td>RT @ChampionsLeague: Two European giants go he...</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-05-26 13:18:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            id  \\\n",
       "0           0  1.000366e+18   \n",
       "1           4  1.000366e+18   \n",
       "2           5  1.000366e+18   \n",
       "3           7  1.000366e+18   \n",
       "4           8  1.000366e+18   \n",
       "\n",
       "                                                text lang  \\\n",
       "0  MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...   en   \n",
       "1  RT @ECG_Unofficial: We will like to categorica...   en   \n",
       "2  Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...   en   \n",
       "3  RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...   en   \n",
       "4  RT @ChampionsLeague: Two European giants go he...   en   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0                                                NaN   \n",
       "1  {'created_at': 'Sat May 26 11:14:44 +0000 2018...   \n",
       "2                                                NaN   \n",
       "3  {'created_at': 'Sat May 26 13:13:45 +0000 2018...   \n",
       "4  {'created_at': 'Sat May 26 13:00:01 +0000 2018...   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2018-05-26 13:18:30+00:00   \n",
       "1  2018-05-26 13:18:31+00:00   \n",
       "2  2018-05-26 13:18:31+00:00   \n",
       "3  2018-05-26 13:18:31+00:00   \n",
       "4  2018-05-26 13:18:31+00:00   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'id': 2846595478, 'id_str': '2846595478', 'na...   \n",
       "1  {'id': 902735000445095938, 'id_str': '90273500...   \n",
       "2  {'id': 240672622, 'id_str': '240672622', 'name...   \n",
       "3  {'id': 277019564, 'id_str': '277019564', 'name...   \n",
       "4  {'id': 957644286350315521, 'id_str': '95764428...   \n",
       "\n",
       "                                          tweet_text  is_retweet  \\\n",
       "0  MATCH-DAY\\n\\nReal Madrid vs Liverpool\\n\\n#UCLF...       False   \n",
       "1  RT @ECG_Unofficial: We will like to categorica...        True   \n",
       "2  Real Madrid.... LETS GO!!!!!!!!!!!!!!!!!!!!!!!...       False   \n",
       "3  RT @YNWA_Claire: Please? üôèüèº\\n\\n#UCLFinal https...        True   \n",
       "4  RT @ChampionsLeague: Two European giants go he...        True   \n",
       "\n",
       "      created_at_hour_minute  \n",
       "0  2018-05-26 13:18:00+00:00  \n",
       "1  2018-05-26 13:18:00+00:00  \n",
       "2  2018-05-26 13:18:00+00:00  \n",
       "3  2018-05-26 13:18:00+00:00  \n",
       "4  2018-05-26 13:18:00+00:00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jamie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/jamie/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NLTK libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization <a class=\"anchor\" id=\"tokenization\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization <a class=\"anchor\" id=\"word-tokenization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del SAMPLE_en_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns clean tokenized words for a tweet\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Context specific stop words (refer \"most common words\" section below for identification approach\n",
    "\n",
    "# rt = short for retweet, this does not provide any insights and a column already exists to identify retweets\n",
    "# http & https = the start of web links these provide little value as \"words\", future work: these could be\n",
    "# to build a feature along thelines of \"Contains Web Link?\"\n",
    "# uclfinal, championsleague, championsleaguefinal = \"hashtag\"/topical words, given the original tweet dataset\n",
    "# contained only tweets that had a hashtag of uclfinal these words do not add value to the analysis\n",
    "custom_stopwords = ['rt', 'http', 'https', 'uclfinal', 'championsleague', 'championsleaguefinal']\n",
    "\n",
    "# Combine the two stop words lists\n",
    "stop_words = english_stopwords + custom_stopwords\n",
    "\n",
    "def CleanTokenizedWords(tweet):\n",
    "    word_tokenized = word_tokenize(tweet)\n",
    "\n",
    "    # lowercasing\n",
    "    cleaned_word_tokenized = [word.lower().strip() for word in word_tokenized]\n",
    "    \n",
    "    # replacing some unwanted things\n",
    "    cleaned_word_tokenized = [word.replace('(','').replace(')','') for word in cleaned_word_tokenized if word.isalpha()]\n",
    "    \n",
    "    # removing stopwords\n",
    "    cleaned_word_tokenized = [word for word in cleaned_word_tokenized if word not in stop_words]\n",
    "    \n",
    "    return cleaned_word_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words in tweets\n",
    "en_tweets_df['tokenized_words'] = en_tweets_df.apply(lambda row: CleanTokenizedWords(row['tweet_text']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words <a class=\"anchor\" id=\"most-common-words\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('uclfinal', 457),\n",
       " ('https', 276),\n",
       " ('rt', 251),\n",
       " ('lfc', 121),\n",
       " ('liverpool', 103),\n",
       " ('come', 89),\n",
       " ('reds', 80),\n",
       " ('madrid', 70),\n",
       " ('real', 65),\n",
       " ('championsleague', 58),\n",
       " ('time', 43),\n",
       " ('live', 38),\n",
       " ('go', 35),\n",
       " ('halamadrid', 32),\n",
       " ('ynwa', 30),\n",
       " ('final', 29),\n",
       " ('game', 28),\n",
       " ('realmadrid', 25),\n",
       " ('allez', 23),\n",
       " ('vs', 22),\n",
       " ('let', 22),\n",
       " ('kick', 21),\n",
       " ('turn', 20),\n",
       " ('stream', 19),\n",
       " ('championsleaguefinal', 19),\n",
       " ('anfield', 19),\n",
       " ('believers', 19),\n",
       " ('rocking', 18),\n",
       " ('sound', 18),\n",
       " ('watch', 17),\n",
       " ('win', 17),\n",
       " ('kiev', 17),\n",
       " ('underway', 17),\n",
       " ('v', 16),\n",
       " ('tonight', 16),\n",
       " ('ronaldo', 16),\n",
       " ('dua', 16),\n",
       " ('gt', 16),\n",
       " ('salah', 15),\n",
       " ('league', 15),\n",
       " ('ucl', 14),\n",
       " ('lipa', 14),\n",
       " ('day', 13),\n",
       " ('football', 13),\n",
       " ('champions', 13),\n",
       " ('mobil', 13),\n",
       " ('team', 12),\n",
       " ('walk', 12),\n",
       " ('rmaliv', 12),\n",
       " ('good', 10),\n",
       " ('like', 9),\n",
       " ('never', 9),\n",
       " ('alone', 9),\n",
       " ('one', 9),\n",
       " ('uefa', 9),\n",
       " ('cristiano', 9),\n",
       " ('last', 8),\n",
       " ('performing', 8),\n",
       " ('mo', 8),\n",
       " ('first', 7),\n",
       " ('biggest', 7),\n",
       " ('kickoff', 7),\n",
       " ('almost', 7),\n",
       " ('luck', 7),\n",
       " ('dlipanews', 7),\n",
       " ('know', 7),\n",
       " ('today', 6),\n",
       " ('lets', 6),\n",
       " ('european', 6),\n",
       " ('winner', 6),\n",
       " ('amp', 6),\n",
       " ('may', 6),\n",
       " ('best', 6),\n",
       " ('stadium', 6),\n",
       " ('rmalfc', 6),\n",
       " ('look', 6),\n",
       " ('score', 6),\n",
       " ('follow', 6),\n",
       " ('hd', 5),\n",
       " ('world', 5),\n",
       " ('fans', 5),\n",
       " ('dualipa', 5),\n",
       " ('show', 5),\n",
       " ('us', 5),\n",
       " ('players', 5),\n",
       " ('night', 5),\n",
       " ('great', 5),\n",
       " ('begins', 5),\n",
       " ('way', 5),\n",
       " ('give', 5),\n",
       " ('bagsulebagg', 5),\n",
       " ('gon', 4),\n",
       " ('na', 4),\n",
       " ('watching', 4),\n",
       " ('get', 4),\n",
       " ('hope', 4),\n",
       " ('going', 4),\n",
       " ('make', 4),\n",
       " ('kicks', 4),\n",
       " ('ceremony', 4)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are three key benefits to finding the most common words:\n",
    "    # 1. Further refinements could be made to CleanTokenizedWords in terms of words to exclude\n",
    "    # 2. We can obtain further insights into the data\n",
    "    # 3. Can select key words that could be used to generate features    \n",
    "\n",
    "# Convert tokenized words column into a single list of words\n",
    "words_list = en_tweets_df['tokenized_words'].values.tolist()\n",
    "\n",
    "# Flatten the list\n",
    "flattened_words_list = [j for sub in words_list for j in sub]\n",
    "\n",
    "# Find the most common words\n",
    "fdist = FreqDist(x.lower() for x in flattened_words_list)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "## SCRAP ######################################################\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(':', 3), ('#', 2), ('https', 2), ('MATCH-DAY', 1), ('Real', 1), ('Madrid', 1), ('vs', 1), ('Liverpool', 1), ('UCLFinal', 1), ('LFC', 1), ('Free', 1), ('Live', 1), ('Stream', 1), ('HD', 1), ('Here', 1), ('//t.co/PHAepWsA6o', 1), ('//t.co/T6mWNz14lb', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# word_tokenized = word_tokenize()\n",
    "bow = Counter(en_tweets_df['tokenized_words'][0])\n",
    "print(bow.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MATCH-DAY': 1,\n",
       "         'Real': 1,\n",
       "         'Madrid': 1,\n",
       "         'vs': 1,\n",
       "         'Liverpool': 1,\n",
       "         '#': 2,\n",
       "         'UCLFinal': 1,\n",
       "         'LFC': 1,\n",
       "         'Free': 1,\n",
       "         'Live': 1,\n",
       "         'Stream': 1,\n",
       "         'HD': 1,\n",
       "         'Here': 1,\n",
       "         ':': 3,\n",
       "         'https': 2,\n",
       "         '//t.co/PHAepWsA6o': 1,\n",
       "         '//t.co/T6mWNz14lb': 1})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
